apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: llm-proxy-2
  labels:
    division: field
    org: sa
    team: genai
    cloud.googleapis.com/location: us-central1
  annotations:
    run.googleapis.com/ingress: all
    run.googleapis.com/ingress-status: all
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/maxScale: '2'
        run.googleapis.com/startup-cpu-boost: 'true'
    spec:
      containers:
      - image: us-central1-docker.pkg.dev/elastic-sa/notebook-workshop/llm-proxy
        ports:
        - name: http1
          containerPort: 3000
        env:
        - name: BASE_URL
          value: https://llm-proxy-2-voldmqr2bq-uc.a.run.app
        - name: AZURE_LLM_DEPLOYMENTS
          valueFrom:
            secretKeyRef:
              key: '1'
              name: llm_proxy_endpoints
        - name: SALT
          valueFrom:
            secretKeyRef:
              key: '1'
              name: llm_proxy_salt
        - name: ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              key: '1'
              name: llm_proxy_admin_password
        - name: ELASTIC_APM_SERVER_URL
          valueFrom:
            secretKeyRef:
              key: '1'
              name: llm_proxy_apm_url
        - name: ELASTIC_APM_SECRET_TOKEN
          valueFrom:
            secretKeyRef:
              key: '1'
              name: llm_proxy_apm_token
        livenessProbe:
          initialDelaySeconds: 10
          timeoutSeconds: 1
          periodSeconds: 5
          failureThreshold: 3
          httpGet:
            path: /health
            port: 3000
        startupProbe:
          initialDelaySeconds: 5
          timeoutSeconds: 1
          periodSeconds: 10
          failureThreshold: 3
          httpGet:
            path: /health
            port: 3000
      serviceAccountName: 1059491012611-compute@developer.gserviceaccount.com
